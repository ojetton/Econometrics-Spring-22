---
title: "Core Econometrics III: Problem Set 1"
author: "Owen Jetton"
date: "04/06/2022"
output: pdf_document
---

```{r setup, include=FALSE}
#This code will make knitting faster by saving output of code chunks.
knitr::opts_chunk$set(cache = T)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, tidyverse, stargazer)

setwd("/Users/owenjetton/Documents/PhD Year 1/Homeworks/Spring 2022/Econometrics-Spring-22")

```

# Question 1

```{r Data}
data = read.csv("data-001.csv")

```


# Question 2

```{r Regression, results='asis'}
# Regression
reg1 = lm(data = data,
          formula = income_black_2010 ~ pop_enslaved_1860 + pop_total_1860 + pop_total_2010)
# Get Coefficient on pop_enslaved_1860
q2_coef = reg1$coefficients[["pop_enslaved_1860"]]

# Report the regression results (needs results = 'asis' in code chunk header)
stargazer(reg1, title = "Regression Results", header = F)
```

The coefficient on "pop_enslaved_1860" is `r q2_coef`
This tells us that as the population of enslaved individuals of a county in 1860 increases by 1, the median income for black households in 2010 in that county changes by $ `r q2_coef`

# Question 3

```{r Matrix Regression}
# endogenous variable
Y = as.matrix(data$income_black_2010)

# exogenous variables (with intercept)
X = matrix(c(rep(1, 710), data$pop_enslaved_1860, data$pop_total_1860, data$pop_total_2010), 
                    ncol = 4)

# Performs Regression
reg_q3 = solve(t(X) %*% X) %*% t(X) %*% Y

# Gets wanted coefficient
reg_q3[2,1]
```

The coefficient on "pop_enslaved_1860" is `r reg_q3[2,1]` which is the same as in question 2.


# Question 4

```{r Regression Function}
# Regression function
reg_fun = function(y, x) {
  
  # linear algebra equation
  coef = solve(t(x) %*% x) %*% t(x) %*% y
  
  return(coef)
}
```

Results:

```{r}
reg_fun(Y, X)

```

Success!

# Question 5

```{r Regression function With Standard Errors}

reg_fun2 = function(y, x) {
  
  # coefficient equation
  coef = solve(t(x) %*% x) %*% t(x) %*% y
  
  # standard errors
    # error (residuals)
  e = (y - x %*% coef)
    # variance sigma estimate calculation
  s_sq = (1/(dim(x)[1] - dim(x)[2]-1))*sum(e^2)
  
  # calculate variance matrix
  variance_matrix = s_sq * solve(t(x) %*% x)
  
  # arrange the results
  stnd_errors = sqrt(diag(variance_matrix))
  
  # Combine results
  results = cbind(coef, stnd_errors)
  
  return(results)
  
}

```

Results:

```{r}
reg_fun2(Y, X)

```

My function reports the coefficients and standard errors correctly.

# Question 6

To be approximately correct, the standard errors reported from my function rely on the assumptions of homoskedasticity, nonautocorrelation, and normally distributed errors: $\epsilon | X \sim N(0, \sigma^2 I)$

# Question 7

In order for my coefficients to be interpretable as causal, one needs to assume that the model we're estimating is the true model, that there are no omitted relevant variables, that the exogenous variables are in fact *exogenous*.



# Extra Credit

```{r Extra Credit}

reg_fun3 = function(data, var_y, var_x) {
  
  # turn inputs into matrices
  y = as.matrix(data %>% select(all_of(var_y)))
  
  x = as.matrix(cbind(intercept = c(rep(1, length(y))), 
                      data %>% select(all_of(var_x))))
  
  # coefficient equation
  coef = solve(t(x) %*% x) %*% t(x) %*% y
  
  # standard errors
    # error (residuals)
  e = (y - x %*% coef)
    # standard error calculation
  s_sq = (1/(dim(x)[1] - dim(x)[2]-1))*sum(e^2)
  
  # calculate variance matrix
  variance_matrix = s_sq * solve(t(x) %*% x)
  
  # arrange the results
  stnd_errors = sqrt(diag(variance_matrix))
  
  results = cbind(coef, stnd_errors)
  
  return(results)
  
}
```

# Results:

```{r Extra Credit Results}
reg_fun3(data = data, 
         var_y = c("income_black_2010"), 
         var_x = c("pop_enslaved_1860", "pop_total_1860", "pop_total_2010")
)

```

Success!

